{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from activations import Cosine\n",
    "from networks import WHVIRegression\n",
    "from layers import WHVILinear\n",
    "from torch_datasets import ToyDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)  # Seed for reproducibility\n",
    "\n",
    "# Data\n",
    "dataset = ToyDataset(n=128)\n",
    "data_loader = DataLoader(dataset, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = WHVIRegression([\n",
    "    nn.Linear(1, 128),\n",
    "    Cosine(),\n",
    "    WHVILinear(128, lambda_=0.01),\n",
    "    Cosine(),\n",
    "    WHVILinear(128, lambda_=0.01),\n",
    "    Cosine(),\n",
    "    nn.Linear(128, 1)\n",
    "])\n",
    "\n",
    "gamma=0.0005\n",
    "p = 0.3\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "lr_scheduler = optim.lr_scheduler.LambdaLR(optimizer, lambda t: (1 + gamma * t)**(-p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0] Loss = 496.006, sigma = 1.000\n",
      "[Epoch 100] Loss = 445.901, sigma = 1.000\n",
      "[Epoch 200] Loss = 396.784, sigma = 1.000\n",
      "[Epoch 300] Loss = 348.763, sigma = 1.000\n",
      "[Epoch 400] Loss = 302.299, sigma = 1.000\n",
      "[Epoch 0] Loss = 257.999, sigma = 0.999\n",
      "[Epoch 100] Loss = 202.414, sigma = 0.797\n",
      "[Epoch 200] Loss = 143.937, sigma = 0.569\n",
      "[Epoch 300] Loss = 72.888, sigma = 0.296\n",
      "[Epoch 400] Loss = 3.224, sigma = 0.112\n",
      "[Epoch 500] Loss = -29.751, sigma = 0.098\n",
      "[Epoch 600] Loss = -53.672, sigma = 0.077\n",
      "[Epoch 700] Loss = -57.197, sigma = 0.081\n",
      "[Epoch 800] Loss = -67.332, sigma = 0.084\n",
      "[Epoch 900] Loss = -34.639, sigma = 0.075\n",
      "[Epoch 1000] Loss = -67.592, sigma = 0.077\n",
      "[Epoch 1100] Loss = -53.333, sigma = 0.073\n",
      "[Epoch 1200] Loss = -83.559, sigma = 0.074\n",
      "[Epoch 1300] Loss = -86.521, sigma = 0.069\n",
      "[Epoch 1400] Loss = -74.947, sigma = 0.064\n",
      "[Epoch 1500] Loss = -86.216, sigma = 0.064\n",
      "[Epoch 1600] Loss = -91.580, sigma = 0.060\n",
      "[Epoch 1700] Loss = -79.013, sigma = 0.058\n",
      "[Epoch 1800] Loss = -97.094, sigma = 0.061\n",
      "[Epoch 1900] Loss = -102.470, sigma = 0.055\n",
      "[Epoch 2000] Loss = -96.400, sigma = 0.056\n",
      "[Epoch 2100] Loss = -88.477, sigma = 0.058\n",
      "[Epoch 2200] Loss = -99.689, sigma = 0.054\n",
      "[Epoch 2300] Loss = -97.970, sigma = 0.055\n",
      "[Epoch 2400] Loss = -99.720, sigma = 0.054\n",
      "[Epoch 2500] Loss = -95.334, sigma = 0.046\n",
      "[Epoch 2600] Loss = -98.005, sigma = 0.057\n",
      "[Epoch 2700] Loss = -104.133, sigma = 0.049\n",
      "[Epoch 2800] Loss = -113.095, sigma = 0.044\n",
      "[Epoch 2900] Loss = -97.307, sigma = 0.046\n",
      "[Epoch 3000] Loss = -107.139, sigma = 0.046\n",
      "[Epoch 3100] Loss = -102.780, sigma = 0.042\n",
      "[Epoch 3200] Loss = -113.215, sigma = 0.042\n",
      "[Epoch 3300] Loss = -109.251, sigma = 0.045\n",
      "[Epoch 3400] Loss = -115.594, sigma = 0.045\n",
      "[Epoch 3500] Loss = -103.658, sigma = 0.040\n",
      "[Epoch 3600] Loss = -115.889, sigma = 0.041\n",
      "[Epoch 3700] Loss = -119.680, sigma = 0.040\n",
      "[Epoch 3800] Loss = -83.886, sigma = 0.039\n",
      "[Epoch 3900] Loss = -98.608, sigma = 0.039\n",
      "[Epoch 4000] Loss = -120.376, sigma = 0.038\n",
      "[Epoch 4100] Loss = -122.409, sigma = 0.037\n",
      "[Epoch 4200] Loss = -120.915, sigma = 0.038\n",
      "[Epoch 4300] Loss = -117.907, sigma = 0.036\n",
      "[Epoch 4400] Loss = -116.976, sigma = 0.039\n",
      "[Epoch 4500] Loss = -117.551, sigma = 0.036\n",
      "[Epoch 4600] Loss = -116.595, sigma = 0.035\n",
      "[Epoch 4700] Loss = -121.495, sigma = 0.037\n",
      "[Epoch 4800] Loss = -113.256, sigma = 0.036\n",
      "[Epoch 4900] Loss = -124.673, sigma = 0.035\n"
     ]
    }
   ],
   "source": [
    "net.train_model(data_loader, optimizer, epochs2 = 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval()\n",
    "net.eval_samples = 500\n",
    "x_test = torch.reshape(torch.linspace(-2, 3, 1000), (-1, 1))\n",
    "y_test = dataset.f(x_test)\n",
    "y_pred = net(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.ylim(-1, 2.5)\n",
    "plt.xlim(-2, 3)\n",
    "for i in range(y_pred.size()[2]):\n",
    "    plt.plot(\n",
    "        x_test.numpy().ravel(),\n",
    "        y_pred[..., i].detach().numpy().ravel(),\n",
    "        c='r', \n",
    "        alpha=0.01\n",
    "    )\n",
    "\n",
    "plt.scatter(dataset.x, dataset.y, ec='k', label='Noisy training measurements')\n",
    "plt.plot(x_test, y_test, label='True function')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
